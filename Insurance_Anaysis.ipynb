{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Practice Project: Insurance Cost Analysis**\n",
    "\n",
    "In this project, you have to perform analytics operations on an insurance database that uses the below mentioned parameters.\n",
    "\n",
    "| Parameter |Description| Content type |\n",
    "|---|----|---|\n",
    "|age| Age in years| integer |\n",
    "|gender| Male or Female|integer (1 or 2)|\n",
    "| bmi | Body mass index | float |\n",
    "|no_of_children| Number of children | integer|\n",
    "|smoker| Whether smoker or not | integer (0 or 1)|\n",
    "|region| Which US region - NW, NE, SW, SE | integer (1,2,3 or 4 respectively)| \n",
    "|charges| Annual Insurance charges in USD | float|\n",
    "\n",
    "## Objectives \n",
    "In this project, you will:\n",
    " - Load the data as a `pandas` dataframe\n",
    " - Clean the data, taking care of the blank entries\n",
    " - Run exploratory data analysis (EDA) and identify the attributes that most affect the `charges`\n",
    " - Develop single variable and multi variable Linear Regression models for predicting the `charges`\n",
    " - Use Ridge regression to refine the performance of Linear regression models. \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n",
    "*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "_We recommend you import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset to this lab environment\n",
    "\n",
    "Run the cell below to load the dataset to this lab environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'medical_insurance_dataset.csv'\n",
    "df = pd.read_csv(filepath, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 : Import the dataset\n",
    "\n",
    "Import the dataset into a `pandas` dataframe. Note that there are currently no headers in the CSV file. \n",
    "\n",
    "Print the first 10 rows of the dataframe to confirm successful loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the headers to the dataframe, as mentioned in the project scenario. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=['age','gender','bmi','no_of_children','smoker','region','charges']\n",
    "df.columns=headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now, replace the '?' entries with 'NaN' values.\n",
    "This is being done to replace unwanted entries to more approachable NaN value which we can identify easily with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('?',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 : Data Wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `dataframe.info()` to identify the columns that have some 'Null' (or NaN) information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle missing data:\n",
    "\n",
    "- For continuous attributes (e.g., age), replace missing values with the mean.\n",
    "- For categorical attributes (e.g., smoker), replace missing values with the most frequent value.\n",
    "- Update the data types of the respective columns.\n",
    "- Verify the update using `df.info()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing empty cells in 'age' with mean age\n",
    "mean_age=df['age'].astype('float').mean()\n",
    "df['age'].replace(np.nan, mean_age,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing empty cells in 'smoker' with most frequent value\n",
    "is_smoker=df['smoker'].value_counts().idxmax()\n",
    "df['smoker'].replace(np.nan,is_smoker,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating data types of 'age' and 'smoker' columns to int\n",
    "df[['age','smoker']] = df[['age','smoker']].astype('int')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note, that the `charges` column has values which are more than 2 decimal places long. Update the `charges` column such that all values are rounded to nearest 2 decimal places. Verify conversion by printing the first 5 values of the updated dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['charges'] = round(df['charges'],2)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 : Exploratory Data Analysis (EDA)\n",
    "\n",
    "Implement the regression plot for `charges` with respect to `bmi`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"bmi\", y=\"charges\", data=df, line_kws={\"color\": \"red\"})\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the box plot for `charges` with respect to `smoker`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='smoker',y='charges',data=df,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the correlation matrix for the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `heatmap`of the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 : Model Development\n",
    "\n",
    "Fit a linear regression model that may be used to predict the `charges` value, just by using the `smoker` attribute of the dataset. Print the $ R^2 $ score of this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['smoker']]\n",
    "y=df[['charges']]\n",
    "lm=LinearRegression()\n",
    "lm.fit(x,y)\n",
    "print(f\"R-squared score: {lm.score(x,y):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The R-squared of 0.62 indicates that approximately 62% of the variance in charges can be explained by the smoker attribute alone._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a linear regression model that may be used to predict the `charges` value, just by using all other attributes of the dataset. Print the $ R^2 $ score of this model. You should see an improvement in the performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=df[[\"age\", \"gender\", \"bmi\", \"no_of_children\", \"smoker\", \"region\"]]\n",
    "lm.fit(z,y)\n",
    "print(f\"R-squared score: {lm.score(z,y):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The R-squared of 0.75 indicates that approximately 75% of the variance in charges can be explained by all attribute combined._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training pipeline that uses `StandardScaler()`, `PolynomialFeatures()` and `LinearRegression()` to create a model that can predict the `charges` value using all the other attributes of the dataset. There should be even further improvement in the performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__StandardScaler prevents features with a large range (like charges) from dominating the model over those with a smaller range (age).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Default polynomial degree here is 2.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=[('scale',StandardScaler()),('poly',PolynomialFeatures(include_bias=False)),('model',LinearRegression())]\n",
    "pipe=Pipeline(input)\n",
    "z=z.astype(\"float\")\n",
    "pipe.fit(z,y)\n",
    "#print(pipe.score(z,y))\n",
    "ypipe=pipe.predict(z)\n",
    "print(f\"R-squared score: {r2_score(y,ypipe):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The R-squared of 0.84 indicates that approximately 84% of the variance in charges can be explained by all attribute combined._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5 : Model Refinement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing subsets, assuming that 20% of the data will be reserved for testing.\n",
    "__This helps you perform unbiased model evaluation and validation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(z,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a `Ridge` regressor that used hyperparameter $ \\alpha = 0.1 $. Fit the model using training data data subset. Print the $ R^2 $ score for the testing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ridge regression helps to prevent overfitting by adding a penalty term to the model's coefficients.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeModel=Ridge(alpha=0.1)\n",
    "ridgeModel.fit(x_train,y_train)\n",
    "yhat=ridgeModel.predict(x_test)\n",
    "print(f\"R-squared score: {r2_score(y_test,yhat):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The R-squared of 0.67 indicates that approximately 67% of the variance in charges can be explained by all attribute combined._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `polynomial` transformation to the training parameters with `degree=2`. Use this transformed feature set to fit the same regression model, as above, using the training subset. Print the $ R^2 $ score for the testing subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=PolynomialFeatures(degree=2)\n",
    "x_train_pr=pr.fit_transform(x_train)\n",
    "x_test_pr=pr.fit_transform(x_test)\n",
    "ridgeModel.fit(x_train_pr,y_train)\n",
    "yhat=ridgeModel.predict(x_test_pr)\n",
    "print(f\"R-squared score: {r2_score(y_test,yhat):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The R-squared of 0.78 indicates that approximately 78% of the variance in charges can be explained by all attribute combined._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cross_Val_Score` method to check r-square value with folds = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre=LinearRegression()\n",
    "Rcross = cross_val_score(lre,z,y,cv=4)\n",
    "print(f\"R-squared score mean: {Rcross.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-square score summary for different models with all the attributes\n",
    "\n",
    "| MLR | Normalized Polynomial Model | Ridge Model $ train-test = 0.2, \\alpha = 0.1 $ | Polynomial Ridge Model $ degree = 2 $ | Cross Value cv=4 |\n",
    "|:--------:|:--------:|:--------:|:--------:|:--------:|\n",
    "| 0.75 | 0.84 | 0.67 | 0.78 | 0.75 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Summary\n",
    "\n",
    "This project aimed to predict __insurance charges__ using various machine learning models. The initial Exploratory Data Analysis (EDA) revealed that the relationship between features and the target was __non-linear__, suggesting that more complex models would be needed.\n",
    "\n",
    "We began with a __Multiple Linear Regression (MLR)__ model, which served as our baseline and achieved an R-squared score of __0.75__. To capture the non-linear relationships, we then used a __Normalized Polynomial Model__, which significantly improved performance to an R-squared of __0.84__.\n",
    "\n",
    "To address potential overfitting, we explored __Ridge Regularization__. While the basic Ridge model underperformed (R-squared = 0.67) due to an overly aggressive penalty, the __Polynomial Ridge Model__ still showed a strong R-squared of __0.78__.\n",
    "\n",
    "Ultimately, the __Normalized Polynomial Model__ proved to be the most effective for this dataset, providing the best predictive power. This analysis demonstrates the importance of both __feature engineering__ (using polynomial features) and __hyperparameter tuning__ (adjusting the alpha value in the Ridge model) to build a robust predictive model.\n",
    "\n",
    "_Note: Only Project Summary is AI generated._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-09-16|0.1|Abhishek Gagneja|Initial Version Created|\n",
    "|2023-09-19|0.2|Vicky Kuo|Reviewed and Revised|\n",
    "--!>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "prev_pub_hash": "447f34cd0035de4dba09d5edf5d2fe7b55d61776ea4c8a482c66d40d8e2dc2be"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
